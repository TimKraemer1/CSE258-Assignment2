{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12d270cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e34f98a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 88310it [01:23, 1051.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 88310 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling interactions: 100%|██████████| 88310/88310 [00:18<00:00, 4846.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = []\n",
    "with gzip.open(\"dataset/australian_users_items.json.gz\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f, desc=\"Loading data\"):\n",
    "        obj = ast.literal_eval(line)\n",
    "        data.append(obj)\n",
    "\n",
    "print(f\"Loaded {len(data)} users\")\n",
    "\n",
    "# Compile interactions\n",
    "user_games = defaultdict(list)  # user_id -> list of (game_id, playtime)\n",
    "game_users = defaultdict(list)  # game_id -> list of (user_id, playtime)\n",
    "\n",
    "for user_data in tqdm(data, desc=\"Compiling interactions\"):\n",
    "    user_id = user_data['user_id']\n",
    "    \n",
    "    for item in user_data['items']:\n",
    "        game_id = item['item_id']\n",
    "        playtime = item['playtime_forever']\n",
    "        \n",
    "        # Only include games that have been played (playtime > 0)\n",
    "        if playtime > 0:\n",
    "            user_games[user_id].append((game_id, playtime))\n",
    "            game_users[game_id].append((user_id, playtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae85f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 68403, Games: 10050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Positive Samples: 100%|██████████| 68403/68403 [00:13<00:00, 5104.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive interactions: 3285246\n",
      "Train positive: 2628196, Test positive: 657050\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "all_users = list(user_games.keys())\n",
    "all_games = list(game_users.keys())\n",
    "\n",
    "user_id_to_idx = {uid: idx for idx, uid in enumerate(all_users)}\n",
    "game_id_to_idx = {gid: idx for idx, gid in enumerate(all_games)}\n",
    "idx_to_user_id = {idx: uid for uid, idx in user_id_to_idx.items()}\n",
    "idx_to_game_id = {idx: gid for gid, idx in game_id_to_idx.items()}\n",
    "\n",
    "print(f\"Users: {len(all_users)}, Games: {len(all_games)}\")\n",
    "\n",
    "# collect all positive interactions\n",
    "positive_interactions = []\n",
    "user_positive_games = defaultdict(set)\n",
    "\n",
    "for user_id, games in tqdm(user_games.items(), desc=\"Collecting Positive Samples\"):\n",
    "    user_idx = user_id_to_idx[user_id]\n",
    "    for game_id, playtime in games:\n",
    "        game_idx = game_id_to_idx[game_id]\n",
    "        positive_interactions.append((user_idx, game_idx, 1, playtime)) # label = 1\n",
    "        user_positive_games[user_idx].add(game_idx)\n",
    "\n",
    "print(f\"Total positive interactions: {len(positive_interactions)}\")\n",
    "\n",
    "# split positive interactions into train/test \n",
    "random.shuffle(positive_interactions)\n",
    "split_idx = int(0.8 * len(positive_interactions))\n",
    "train_positive = positive_interactions[:split_idx]\n",
    "test_positive = positive_interactions[split_idx:]\n",
    "\n",
    "print(f\"Train positive: {len(train_positive)}, Test positive: {len(test_positive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f37437a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate negative samples\n",
    "def generate_negative_samples(positive_samples, user_positive_games, num_games, neg_ratio=1):\n",
    "    negative_samples = []\n",
    "\n",
    "    for user_idx, game_idx, _, _ in tqdm(positive_samples, desc=\"Generating negative samples\"):\n",
    "        for _ in range(neg_ratio):\n",
    "            neg_game_idx = random.randint(0, num_games - 1)\n",
    "            while neg_game_idx in user_positive_games[user_idx]:\n",
    "                neg_game_idx = random.randint(0, num_games - 1)\n",
    "            \n",
    "            negative_samples.append((user_idx, neg_game_idx, 0, 0))\n",
    "    return negative_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e44861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating negative samples: 100%|██████████| 2628196/2628196 [00:32<00:00, 81797.52it/s] \n",
      "Generating negative samples: 100%|██████████| 657050/657050 [00:11<00:00, 56072.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train negative: 2628196, Test negative: 657050\n",
      "\n",
      "Final dataset sizes:\n",
      "Train: 5256392 (2628196 pos, 2628196 neg)\n",
      "Test: 1314100 (657050 pos, 657050 neg)\n",
      "\n",
      "Train labels distribution: [2628196 2628196]\n",
      "Test labels distribution: [657050 657050]\n"
     ]
    }
   ],
   "source": [
    "train_negative = generate_negative_samples(train_positive, user_positive_games, len(all_games), neg_ratio=1)\n",
    "test_negative = generate_negative_samples(test_positive, user_positive_games, len(all_games), neg_ratio=1)\n",
    "\n",
    "print(f\"Train negative: {len(train_negative)}, Test negative: {len(test_negative)}\")\n",
    "\n",
    "train_data = train_positive + train_negative\n",
    "test_data = test_positive + test_negative\n",
    "\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "print(f\"\\nFinal dataset sizes:\")\n",
    "print(f\"Train: {len(train_data)} ({len(train_positive)} pos, {len(train_negative)} neg)\")\n",
    "print(f\"Test: {len(test_data)} ({len(test_positive)} pos, {len(test_negative)} neg)\")\n",
    "\n",
    "# Convert to arrays for easy use\n",
    "train_users = np.array([x[0] for x in train_data])\n",
    "train_games = np.array([x[1] for x in train_data])\n",
    "train_labels = np.array([x[2] for x in train_data])\n",
    "train_playtimes = np.array([x[3] for x in train_data])\n",
    "\n",
    "test_users = np.array([x[0] for x in test_data])\n",
    "test_games = np.array([x[1] for x in test_data])\n",
    "test_labels = np.array([x[2] for x in test_data])\n",
    "test_playtimes = np.array([x[3] for x in test_data])\n",
    "\n",
    "print(f\"\\nTrain labels distribution: {np.bincount(train_labels)}\")\n",
    "print(f\"Test labels distribution: {np.bincount(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e27c72",
   "metadata": {},
   "source": [
    "# Random Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e7040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Accuracy: 0.4994\n",
      "Random AUC: 0.4996\n"
     ]
    }
   ],
   "source": [
    "# Random predictions\n",
    "random_preds = np.random.rand(len(test_labels))\n",
    "random_auc = roc_auc_score(test_labels, random_preds)\n",
    "print(f\"Random AUC: {random_auc:.4f}\")\n",
    "\n",
    "binary_preds = (random_preds > 0.5).astype(int)\n",
    "accuracy = (binary_preds == test_labels).mean()\n",
    "print(f\"Random Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae6ae0",
   "metadata": {},
   "source": [
    "# Popularity Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c97a2b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity AUC: 0.9454\n",
      "Popularity Accuracy: 0.8749\n"
     ]
    }
   ],
   "source": [
    "# Count how many users played each game\n",
    "game_popularity = {}\n",
    "for game_idx in range(len(all_games)):\n",
    "    game_popularity[game_idx] = len(game_users[idx_to_game_id[game_idx]])\n",
    "\n",
    "# Predict based on game popularity AUC\n",
    "pop_preds = np.array([game_popularity[game_idx] for game_idx in test_games])\n",
    "pop_auc = roc_auc_score(test_labels, pop_preds)\n",
    "print(f\"Popularity AUC: {pop_auc:.4f}\")\n",
    "\n",
    "# Accuracy\n",
    "threshold = np.median(pop_preds)\n",
    "pop_preds_binary = (pop_preds >= threshold).astype(int)\n",
    "accuracy = (pop_preds_binary == test_labels).mean()\n",
    "print(f\"Popularity Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a0a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
