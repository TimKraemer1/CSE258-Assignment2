{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45995a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcf6349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = []\n",
    "with gzip.open(\"dataset/australian_users_items.json.gz\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f, desc=\"Loading data\"):\n",
    "        obj = ast.literal_eval(line)\n",
    "        data.append(obj)\n",
    "\n",
    "print(f\"Loaded {len(data)} users\")\n",
    "\n",
    "# Compile interactions\n",
    "user_games = defaultdict(list)  # user_id -> list of (game_id, playtime)\n",
    "game_users = defaultdict(list)  # game_id -> list of (user_id, playtime)\n",
    "\n",
    "for user_data in tqdm(data, desc=\"Compiling interactions\"):\n",
    "    user_id = user_data['user_id']\n",
    "    \n",
    "    for item in user_data['items']:\n",
    "        game_id = item['item_id']\n",
    "        playtime = item['playtime_forever']\n",
    "        \n",
    "        # Only include games that have been played (playtime > 0)\n",
    "        if playtime > 0:\n",
    "            user_games[user_id].append((game_id, playtime))\n",
    "            game_users[game_id].append((user_id, playtime))\n",
    "\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"Total users with playtime > 0: {len(user_games)}\")\n",
    "print(f\"Total unique games played: {len(game_users)}\")\n",
    "print(f\"Total interactions (user-game pairs): {sum(len(games) for games in user_games.values())}\")\n",
    "print(f\"Average games per user: {sum(len(games) for games in user_games.values()) / len(user_games):.2f}\")\n",
    "print(f\"Average users per game: {sum(len(users) for users in game_users.values()) / len(game_users):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf925612",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "all_users = list(user_games.keys())\n",
    "all_games = list(game_users.keys())\n",
    "\n",
    "user_id_to_idx = {uid: idx for idx, uid in enumerate(all_users)}\n",
    "game_id_to_idx = {gid: idx for idx, gid in enumerate(all_games)}\n",
    "idx_to_user_id = {idx: uid for uid, idx in user_id_to_idx.items()}\n",
    "idx_to_game_id = {idx: gid for gid, idx in game_id_to_idx.items()}\n",
    "\n",
    "print(f\"Users: {len(all_users)}, Games: {len(all_games)}\")\n",
    "\n",
    "# collect all positive interactions\n",
    "positive_interactions = []\n",
    "user_positive_games = defaultdict(set)\n",
    "\n",
    "for user_id, games in tqdm(user_games.items(), desc=\"Collecting Positive Samples\"):\n",
    "    user_idx = user_id_to_idx[user_id]\n",
    "    for game_id, playtime in games:\n",
    "        game_idx = game_id_to_idx[game_id]\n",
    "        positive_interactions.append((user_idx, game_idx, 1, playtime)) # label = 1\n",
    "        user_positive_games[user_idx].add(game_idx)\n",
    "\n",
    "print(f\"Total positive interactions: {len(positive_interactions)}\")\n",
    "\n",
    "# split positive interactions into train/test \n",
    "random.shuffle(positive_interactions)\n",
    "split_idx = int(0.8 * len(positive_interactions))\n",
    "train_positive = positive_interactions[:split_idx]\n",
    "test_positive = positive_interactions[split_idx:]\n",
    "\n",
    "print(f\"Train positive: {len(train_positive)}, Test positive: {len(test_positive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f999d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate negative samples\n",
    "def generate_negative_samples(positive_samples, user_positive_games, num_games, neg_ratio=1):\n",
    "    negative_samples = []\n",
    "\n",
    "    for user_idx, game_idx, _, _ in tqdm(positive_samples, desc=\"Generating negative samples\"):\n",
    "        for _ in range(neg_ratio):\n",
    "            neg_game_idx = random.randint(0, num_games - 1)\n",
    "            while neg_game_idx in user_positive_games[user_idx]:\n",
    "                neg_game_idx = random.randint(0, num_games - 1)\n",
    "            \n",
    "            negative_samples.append((user_idx, neg_game_idx, 0, 0))\n",
    "    return negative_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc63ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_negative = generate_negative_samples(train_positive, user_positive_games, len(all_games), neg_ratio=1)\n",
    "test_negative = generate_negative_samples(test_positive, user_positive_games, len(all_games), neg_ratio=1)\n",
    "\n",
    "print(f\"Train negative: {len(train_negative)}, Test negative: {len(test_negative)}\")\n",
    "\n",
    "train_data = train_positive + train_negative\n",
    "test_data = test_positive + test_negative\n",
    "\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "print(f\"\\nFinal dataset sizes:\")\n",
    "print(f\"Train: {len(train_data)} ({len(train_positive)} pos, {len(train_negative)} neg)\")\n",
    "print(f\"Test: {len(test_data)} ({len(test_positive)} pos, {len(test_negative)} neg)\")\n",
    "\n",
    "# Convert to arrays for easy use\n",
    "train_users = np.array([x[0] for x in train_data])\n",
    "train_games = np.array([x[1] for x in train_data])\n",
    "train_labels = np.array([x[2] for x in train_data])\n",
    "train_playtimes = np.array([x[3] for x in train_data])\n",
    "\n",
    "test_users = np.array([x[0] for x in test_data])\n",
    "test_games = np.array([x[1] for x in test_data])\n",
    "test_labels = np.array([x[2] for x in test_data])\n",
    "test_playtimes = np.array([x[3] for x in test_data])\n",
    "\n",
    "print(f\"\\nTrain labels distribution: {np.bincount(train_labels)}\")\n",
    "print(f\"Test labels distribution: {np.bincount(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7425ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "EMBEDDING_DIM = 64\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 8192\n",
    "EPOCHS = 10\n",
    "\n",
    "# Dataset class\n",
    "class GameDataset(Dataset):\n",
    "    def __init__(self, users, games, labels):\n",
    "        self.users = torch.LongTensor(users)\n",
    "        self.games = torch.LongTensor(games)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.games[idx], self.labels[idx]\n",
    "\n",
    "# Matrix Factorization Model\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_games, embedding_dim=64):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        \n",
    "        # User and game embeddings\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.game_embedding = nn.Embedding(num_games, embedding_dim)\n",
    "        \n",
    "        # Bias terms\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.game_bias = nn.Embedding(num_games, 1)\n",
    "        self.global_bias = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.game_embedding.weight, std=0.01)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.game_bias.weight)\n",
    "    \n",
    "    def forward(self, user_ids, game_ids):\n",
    "        # Get embeddings\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        game_emb = self.game_embedding(game_ids)\n",
    "        \n",
    "        # Dot product of embeddings\n",
    "        dot_product = (user_emb * game_emb).sum(dim=1, keepdim=True)\n",
    "        \n",
    "        # Add biases\n",
    "        user_b = self.user_bias(user_ids)\n",
    "        game_b = self.game_bias(game_ids)\n",
    "        \n",
    "        # Final prediction\n",
    "        prediction = dot_product + user_b + game_b + self.global_bias\n",
    "        \n",
    "        return prediction.squeeze()\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = GameDataset(train_users, train_games, train_labels)\n",
    "test_dataset = GameDataset(test_users, test_games, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "# device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device = torch.device ('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = MatrixFactorization(\n",
    "    num_users=len(all_users),\n",
    "    num_games=len(all_games),\n",
    "    embedding_dim=EMBEDDING_DIM\n",
    ").to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "\n",
    "print(f\"\\nModel: {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "print(f\"Training on {len(train_dataset)} samples, testing on {len(test_dataset)} samples\")\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for users, games, labels in pbar:\n",
    "        users, games, labels = users.to(device), games.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, games)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for users, games, labels in loader:\n",
    "            users, games, labels = users.to(device), games.to(device), labels.to(device)\n",
    "            predictions = model(users, games)\n",
    "            \n",
    "            # Apply sigmoid for probabilities\n",
    "            probs = torch.sigmoid(predictions)\n",
    "            \n",
    "            all_preds.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    acc = accuracy_score(all_labels, all_preds > 0.5)\n",
    "    \n",
    "    return auc, acc\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nStarting training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_auc, train_acc = evaluate(model, train_loader, device)\n",
    "    test_auc, test_acc = evaluate(model, test_loader, device)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, AUC: {train_auc:.4f}, Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Test  AUC: {test_auc:.4f}, Acc: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
